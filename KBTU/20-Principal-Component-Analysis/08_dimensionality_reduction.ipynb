{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 8 â€“ Dimensionality Reduction**\n",
    "\n",
    "_This notebook contains all the sample code and solutions to the exercises in chapter 8._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection methods\n",
    "Build 3D dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA using SVD decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the `svd()` function returns `U`, `s` and `Vt`, where `Vt` is equal to $\\mathbf{V}^T$, the transpose of the matrix $\\mathbf{V}$. Earlier versions of the book mistakenly said that it returned `V` instead of `Vt`. Also, Equation 8-1 should actually contain $\\mathbf{V}$ instead of $\\mathbf{V}^T$, like this:\n",
    "\n",
    "$\n",
    "\\mathbf{V} =\n",
    "\\begin{pmatrix}\n",
    "  \\mid & \\mid & & \\mid \\\\\n",
    "  \\mathbf{c_1} & \\mathbf{c_2} & \\cdots & \\mathbf{c_n} \\\\\n",
    "  \\mid & \\mid & & \\mid\n",
    "\\end{pmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "S = np.zeros(X_centered.shape)\n",
    "S[:n, :n] = np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X_centered, U.dot(S).dot(Vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2D_using_svd = X2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Scikit-Learn, PCA is really trivial. It even takes care of mean centering for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26203346,  0.42067648],\n",
       "       [-0.08001485, -0.35272239],\n",
       "       [ 1.17545763,  0.36085729],\n",
       "       [ 0.89305601, -0.30862856],\n",
       "       [ 0.73016287, -0.25404049]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26203346,  0.42067648],\n",
       "       [-0.08001485, -0.35272239],\n",
       "       [ 1.17545763,  0.36085729],\n",
       "       [ 0.89305601, -0.30862856],\n",
       "       [ 0.73016287, -0.25404049]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D_using_svd[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice that running PCA multiple times on slightly different datasets may result in different results. In general the only difference is that some axes may be flipped. In this example, PCA using Scikit-Learn gives the same projection as the one given by the SVD approach, except both axes are flipped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X2D, -X2D_using_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recover the 3D points projected on the plane (PCA 2D subspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3D_inv = pca.inverse_transform(X2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there was some loss of information during the projection step, so the recovered 3D points are not exactly equal to the original 3D points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X3D_inv, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the reconstruction error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010170337792848549"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sum(np.square(X3D_inv - X), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse transform in the SVD approach looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3D_inv_using_svd = X2D_using_svd.dot(Vt[:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructions from both methods are not identical because Scikit-Learn's `PCA` class automatically takes care of reversing the mean centering, but if we subtract the mean, we get the same reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X3D_inv_using_svd, X3D_inv - pca.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PCA` object gives access to the principal components that it computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93636116, -0.29854881, -0.18465208],\n",
       "       [ 0.34027485, -0.90119108, -0.2684542 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to the first two principal components computed using the SVD method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93636116,  0.29854881,  0.18465208],\n",
       "       [-0.34027485,  0.90119108,  0.2684542 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the axes are flipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the explained variance ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84248607, 0.14631839])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension explains 84.2% of the variance, while the second explains 14.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By projecting down to 2D, we lost about 1.1% of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011195535570688975"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to compute the explained variance ratio using the SVD approach (recall that `s` is the diagonal of the matrix `S`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84248607, 0.14631839, 0.01119554])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(s) / np.square(s).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's generate some nice figures! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility class to draw 3D arrows (copied from http://stackoverflow.com/questions/11140163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Express the plane as a function of x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = [-1.8, 1.8, -1.3, 1.3, -1.0, 1.0]\n",
    "\n",
    "x1s = np.linspace(axes[0], axes[1], 10)\n",
    "x2s = np.linspace(axes[2], axes[3], 10)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "C = pca.components_\n",
    "R = C.T.dot(C)\n",
    "z = (R[0, 2] * x1 + R[1, 2] * x2) / (1 - R[2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 3D dataset, the plane and the projections on that plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x273.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X3D_above = X[X[:, 2] > X3D_inv[:, 2]]\n",
    "X3D_below = X[X[:, 2] <= X3D_inv[:, 2]]\n",
    "\n",
    "ax.plot(X3D_below[:, 0], X3D_below[:, 1], X3D_below[:, 2], \"bo\", alpha=0.5)\n",
    "\n",
    "ax.plot_surface(x1, x2, z, alpha=0.2, color=\"k\")\n",
    "np.linalg.norm(C, axis=0)\n",
    "ax.add_artist(Arrow3D([0, C[0, 0]],[0, C[0, 1]],[0, C[0, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "ax.add_artist(Arrow3D([0, C[1, 0]],[0, C[1, 1]],[0, C[1, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "ax.plot([0], [0], [0], \"k.\")\n",
    "\n",
    "for i in range(m):\n",
    "    if X[i, 2] > X3D_inv[i, 2]:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\")\n",
    "    else:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\", color=\"#505050\")\n",
    "    \n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k+\")\n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k.\")\n",
    "ax.plot(X3D_above[:, 0], X3D_above[:, 1], X3D_above[:, 2], \"bo\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "# Note: If you are using Matplotlib 3.0.0, it has a bug and does not\n",
    "# display 3D graphs properly.\n",
    "# See https://github.com/matplotlib/matplotlib/issues/12239\n",
    "# You should upgrade to a later version. If you cannot, then you can\n",
    "# use the following workaround before displaying each 3D graph:\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, aspect='equal')\n",
    "\n",
    "ax.plot(X2D[:, 0], X2D[:, 1], \"k+\")\n",
    "ax.plot(X2D[:, 0], X2D[:, 1], \"k.\")\n",
    "ax.plot([0], [0], \"ko\")\n",
    "ax.arrow(0, 0, 0, 1, head_width=0.05, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "ax.arrow(0, 0, 1, 0, head_width=0.05, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "ax.set_xlabel(\"$z_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "ax.axis([-1.5, 1.3, -1.2, 1.2])\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold learning\n",
    "Swiss roll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = [-11.5, 14, -2, 23, -12, 15]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=t, cmap=plt.cm.hot)\n",
    "ax.view_init(10, -70)\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=t, cmap=plt.cm.hot)\n",
    "plt.axis(axes[:4])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(t, X[:, 1], c=t, cmap=plt.cm.hot)\n",
    "plt.axis([4, 15, axes[2], axes[3]])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "save_fig(\"squished_swiss_roll_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "axes = [-11.5, 14, -2, 23, -12, 15]\n",
    "\n",
    "x2s = np.linspace(axes[2], axes[3], 10)\n",
    "x3s = np.linspace(axes[4], axes[5], 10)\n",
    "x2, x3 = np.meshgrid(x2s, x3s)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "\n",
    "positive_class = X[:, 0] > 5\n",
    "X_pos = X[positive_class]\n",
    "X_neg = X[~positive_class]\n",
    "ax.view_init(10, -70)\n",
    "ax.plot(X_neg[:, 0], X_neg[:, 1], X_neg[:, 2], \"y^\")\n",
    "ax.plot_wireframe(5, x2, x3, alpha=0.5)\n",
    "ax.plot(X_pos[:, 0], X_pos[:, 1], X_pos[:, 2], \"gs\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(t[positive_class], X[positive_class, 1], \"gs\")\n",
    "plt.plot(t[~positive_class], X[~positive_class, 1], \"y^\")\n",
    "plt.axis([4, 15, axes[2], axes[3]])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "\n",
    "positive_class = 2 * (t[:] - 4) > X[:, 1]\n",
    "X_pos = X[positive_class]\n",
    "X_neg = X[~positive_class]\n",
    "ax.view_init(10, -70)\n",
    "ax.plot(X_neg[:, 0], X_neg[:, 1], X_neg[:, 2], \"y^\")\n",
    "ax.plot(X_pos[:, 0], X_pos[:, 1], X_pos[:, 2], \"gs\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(t[positive_class], X[positive_class, 1], \"gs\")\n",
    "plt.plot(t[~positive_class], X[~positive_class, 1], \"y^\")\n",
    "plt.plot([4, 15], [0, 22], \"b-\", linewidth=2)\n",
    "plt.axis([4, 15, axes[2], axes[3]])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = np.pi / 5\n",
    "stretch = 5\n",
    "m = 200\n",
    "\n",
    "np.random.seed(3)\n",
    "X = np.random.randn(m, 2) / 10\n",
    "X = X.dot(np.array([[stretch, 0],[0, 1]])) # stretch\n",
    "X = X.dot([[np.cos(angle), np.sin(angle)], [-np.sin(angle), np.cos(angle)]]) # rotate\n",
    "\n",
    "u1 = np.array([np.cos(angle), np.sin(angle)])\n",
    "u2 = np.array([np.cos(angle - 2 * np.pi/6), np.sin(angle - 2 * np.pi/6)])\n",
    "u3 = np.array([np.cos(angle - np.pi/2), np.sin(angle - np.pi/2)])\n",
    "\n",
    "X_proj1 = X.dot(u1.reshape(-1, 1))\n",
    "X_proj2 = X.dot(u2.reshape(-1, 1))\n",
    "X_proj3 = X.dot(u3.reshape(-1, 1))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot2grid((3,2), (0, 0), rowspan=3)\n",
    "plt.plot([-1.4, 1.4], [-1.4*u1[1]/u1[0], 1.4*u1[1]/u1[0]], \"k-\", linewidth=1)\n",
    "plt.plot([-1.4, 1.4], [-1.4*u2[1]/u2[0], 1.4*u2[1]/u2[0]], \"k--\", linewidth=1)\n",
    "plt.plot([-1.4, 1.4], [-1.4*u3[1]/u3[0], 1.4*u3[1]/u3[0]], \"k:\", linewidth=2)\n",
    "plt.plot(X[:, 0], X[:, 1], \"bo\", alpha=0.5)\n",
    "plt.axis([-1.4, 1.4, -1.4, 1.4])\n",
    "plt.arrow(0, 0, u1[0], u1[1], head_width=0.1, linewidth=5, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "plt.arrow(0, 0, u3[0], u3[1], head_width=0.1, linewidth=5, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "plt.text(u1[0] + 0.1, u1[1] - 0.05, r\"$\\mathbf{c_1}$\", fontsize=22)\n",
    "plt.text(u3[0] + 0.1, u3[1], r\"$\\mathbf{c_2}$\", fontsize=22)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot2grid((3,2), (0, 1))\n",
    "plt.plot([-2, 2], [0, 0], \"k-\", linewidth=1)\n",
    "plt.plot(X_proj1[:, 0], np.zeros(m), \"bo\", alpha=0.3)\n",
    "plt.gca().get_yaxis().set_ticks([])\n",
    "plt.gca().get_xaxis().set_ticklabels([])\n",
    "plt.axis([-2, 2, -1, 1])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot2grid((3,2), (1, 1))\n",
    "plt.plot([-2, 2], [0, 0], \"k--\", linewidth=1)\n",
    "plt.plot(X_proj2[:, 0], np.zeros(m), \"bo\", alpha=0.3)\n",
    "plt.gca().get_yaxis().set_ticks([])\n",
    "plt.gca().get_xaxis().set_ticklabels([])\n",
    "plt.axis([-2, 2, -1, 1])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot2grid((3,2), (2, 1))\n",
    "plt.plot([-2, 2], [0, 0], \"k:\", linewidth=2)\n",
    "plt.plot(X_proj3[:, 0], np.zeros(m), \"bo\", alpha=0.3)\n",
    "plt.gca().get_yaxis().set_ticks([])\n",
    "plt.axis([-2, 2, -1, 1])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1)\n",
    "    mnist.target = mnist.target.astype(np.int64)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9503684424557435"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 154)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "X_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Compressed')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(121)\n",
    "plot_digits(X_train[::2100])\n",
    "plt.title(\"Original\", fontsize=16)\n",
    "plt.subplot(122)\n",
    "plot_digits(X_recovered[::2100])\n",
    "plt.title(\"Compressed\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_pca = X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)\n",
    "for X_batch in np.array_split(X_train, n_batches):\n",
    "    print(\".\", end=\"\") # not shown in the book\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "\n",
    "X_reduced = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recovered_inc_pca = inc_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(121)\n",
    "plot_digits(X_train[::2100])\n",
    "plt.subplot(122)\n",
    "plot_digits(X_recovered_inc_pca[::2100])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_inc_pca = X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results of transforming MNIST using regular PCA and incremental PCA. First, the means are equal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(pca.mean_, inc_pca.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the results are not exactly identical. Incremental PCA gives a very good approximate solution, but it's not perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(X_reduced_pca, X_reduced_inc_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `memmap()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the `memmap()` structure and copy the MNIST data into it. This would typically be done by a first program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_mnist.data\"\n",
    "m, n = X_train.shape\n",
    "\n",
    "X_mm = np.memmap(filename, dtype='float32', mode='write', shape=(m, n))\n",
    "X_mm[:] = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deleting the `memmap()` object will trigger its Python finalizer, which ensures that the data is saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, another program would load the data and use it for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mm = np.memmap(filename, dtype=\"float32\", mode=\"readonly\", shape=(m, n))\n",
    "\n",
    "batch_size = m // n_batches\n",
    "inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
    "inc_pca.fit(X_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=154, svd_solver=\"randomized\", random_state=42)\n",
    "X_reduced = rnd_pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time regular PCA against Incremental PCA and Randomized PCA, for various number of principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for n_components in (2, 10, 154):\n",
    "    print(\"n_components =\", n_components)\n",
    "    regular_pca = PCA(n_components=n_components)\n",
    "    inc_pca = IncrementalPCA(n_components=n_components, batch_size=500)\n",
    "    rnd_pca = PCA(n_components=n_components, random_state=42, svd_solver=\"randomized\")\n",
    "\n",
    "    for pca in (regular_pca, inc_pca, rnd_pca):\n",
    "        t1 = time.time()\n",
    "        pca.fit(X_train)\n",
    "        t2 = time.time()\n",
    "        print(\"    {}: {:.1f} seconds\".format(pca.__class__.__name__, t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare PCA and Randomized PCA for datasets of different sizes (number of instances):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rpca = []\n",
    "times_pca = []\n",
    "sizes = [1000, 10000, 20000, 30000, 40000, 50000, 70000, 100000, 200000, 500000]\n",
    "for n_samples in sizes:\n",
    "    X = np.random.randn(n_samples, 5)\n",
    "    pca = PCA(n_components = 2, svd_solver=\"randomized\", random_state=42)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_rpca.append(t2 - t1)\n",
    "    pca = PCA(n_components = 2)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_pca.append(t2 - t1)\n",
    "\n",
    "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
    "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
    "plt.xlabel(\"n_samples\")\n",
    "plt.ylabel(\"Training time\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"PCA and Randomized PCA time complexity \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's compare their performance on datasets of 2,000 instances with various numbers of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_rpca = []\n",
    "times_pca = []\n",
    "sizes = [1000, 2000, 3000, 4000, 5000, 6000]\n",
    "for n_features in sizes:\n",
    "    X = np.random.randn(2000, n_features)\n",
    "    pca = PCA(n_components = 2, random_state=42, svd_solver=\"randomized\")\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_rpca.append(t2 - t1)\n",
    "    pca = PCA(n_components = 2)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_pca.append(t2 - t1)\n",
    "\n",
    "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
    "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
    "plt.xlabel(\"n_features\")\n",
    "plt.ylabel(\"Training time\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"PCA and Randomized PCA time complexity \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "lin_pca = KernelPCA(n_components = 2, kernel=\"linear\", fit_inverse_transform=True)\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433, fit_inverse_transform=True)\n",
    "sig_pca = KernelPCA(n_components = 2, kernel=\"sigmoid\", gamma=0.001, coef0=1, fit_inverse_transform=True)\n",
    "\n",
    "y = t > 6.9\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for subplot, pca, title in ((131, lin_pca, \"Linear kernel\"), (132, rbf_pca, \"RBF kernel, $\\gamma=0.04$\"), (133, sig_pca, \"Sigmoid kernel, $\\gamma=10^{-3}, r=1$\")):\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    if subplot == 132:\n",
    "        X_reduced_rbf = X_reduced\n",
    "    \n",
    "    plt.subplot(subplot)\n",
    "    #plt.plot(X_reduced[y, 0], X_reduced[y, 1], \"gs\")\n",
    "    #plt.plot(X_reduced[~y, 0], X_reduced[~y, 1], \"y^\")\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot)\n",
    "    plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "    if subplot == 131:\n",
    "        plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "X_inverse = rbf_pca.inverse_transform(X_reduced_rbf)\n",
    "\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "ax.view_init(10, -70)\n",
    "ax.scatter(X_inverse[:, 0], X_inverse[:, 1], X_inverse[:, 2], c=t, cmap=plt.cm.hot, marker=\"x\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_zlabel(\"\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "plt.subplot(132)\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot, marker=\"x\")\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "        (\"kpca\", KernelPCA(n_components=2)),\n",
    "        (\"log_reg\", LogisticRegression(solver=\"liblinear\"))\n",
    "    ])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433,\n",
    "                    fit_inverse_transform=True)\n",
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(X, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)\n",
    "X_reduced = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Unrolled swiss roll using LLE\", fontsize=14)\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot)\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18)\n",
    "plt.axis([-0.065, 0.055, -0.1, 0.12])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDS, Isomap and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2, random_state=42)\n",
    "X_reduced_mds = mds.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "isomap = Isomap(n_components=2)\n",
    "X_reduced_isomap = isomap.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_mnist = mnist[\"data\"]\n",
    "y_mnist = mnist[\"target\"]\n",
    "lda.fit(X_mnist, y_mnist)\n",
    "X_reduced_lda = lda.transform(X_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"MDS\", \"Isomap\", \"t-SNE\"]\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "for subplot, title, X_reduced in zip((131, 132, 133), titles,\n",
    "                                     (X_reduced_mds, X_reduced_isomap, X_reduced_tsne)):\n",
    "    plt.subplot(subplot)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot)\n",
    "    plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "    if subplot == 131:\n",
    "        plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learned_parameters(model):\n",
    "    return [m for m in dir(model)\n",
    "            if m.endswith(\"_\") and not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Material â€“ Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction â€“ Classification _vs_ Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3.5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(X[y==0, 2], X[y==0, 3], \"yo\", label=\"Iris-Setosa\")\n",
    "plt.plot(X[y==1, 2], X[y==1, 3], \"bs\", label=\"Iris-Versicolor\")\n",
    "plt.plot(X[y==2, 2], X[y==2, 3], \"g^\", label=\"Iris-Virginica\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(X[:, 2], X[:, 3], c=\"k\", marker=\".\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.tick_params(labelleft=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Gaussian mixture model (explained below) can actually separate these clusters pretty well (using all 4 features: petal length & width, and sepal length & width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = GaussianMixture(n_components=3, random_state=42).fit(X).predict(X)\n",
    "mapping = np.array([2, 0, 1])\n",
    "y_pred = np.array([mapping[cluster_id] for cluster_id in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[y_pred==0, 2], X[y_pred==0, 3], \"yo\", label=\"Cluster 1\")\n",
    "plt.plot(X[y_pred==1, 2], X[y_pred==1, 3], \"bs\", label=\"Cluster 2\")\n",
    "plt.plot(X[y_pred==2, 2], X[y_pred==2, 3], \"g^\", label=\"Cluster 3\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"upper left\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred==y) / len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by generating some blobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, y=None):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=1)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_clusters(X)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a K-Means clusterer on this dataset. It will try to find each blob's center and assign each instance to the closest blob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each instance was assigned to one of the 5 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred is kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following 5 _centroids_ (i.e., cluster centers) were estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `KMeans` instance preserves the labels of the instances it was trained on. Somewhat confusingly, in this context, the _label_ of an instance is the index of the cluster that instance gets assigned to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can predict the labels of new instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model's decision boundaries. This gives us a _Voronoi diagram_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=30, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=50, linewidths=50,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=True, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    plot_data(X)\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n",
    "save_fig(\"voronoi_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Some of the instances near the edges were probably assigned to the wrong cluster, but overall it looks pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Clustering _vs_ Soft Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than arbitrarily choosing the closest cluster for each instance, which is called _hard clustering_, it might be better measure the distance of each instance to all 5 centroids. This is what the `transform()` method does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that this is indeed the Euclidian distance between each instance and each centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.tile(X_new, (1, k)).reshape(-1, k, 2) - kmeans.cluster_centers_, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Means algorithm is one of the fastest clustering algorithms, but also one of the simplest:\n",
    "* First initialize $k$ centroids randomly: $k$ distinct instances are chosen randomly from the dataset and the centroids are placed at their locations.\n",
    "* Repeat until convergence (i.e., until the centroids stop moving):\n",
    "    * Assign each instance to the closest centroid.\n",
    "    * Update the centroids to be the mean of the instances that are assigned to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `KMeans` class applies an optimized algorithm by default. To get the original K-Means algorithm (for educational purposes only), you must set `init=\"random\"`, `n_init=1`and `algorithm=\"full\"`. These hyperparameters will be explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the K-Means algorithm for 1, 2 and 3 iterations, to see how the centroids move around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_iter1 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=1, random_state=1)\n",
    "kmeans_iter2 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=2, random_state=1)\n",
    "kmeans_iter3 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                     algorithm=\"full\", max_iter=3, random_state=1)\n",
    "kmeans_iter1.fit(X)\n",
    "kmeans_iter2.fit(X)\n",
    "kmeans_iter3.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(321)\n",
    "plot_data(X)\n",
    "plot_centroids(kmeans_iter1.cluster_centers_, circle_color='r', cross_color='w')\n",
    "plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "plt.tick_params(labelbottom=False)\n",
    "plt.title(\"Update the centroids (initially randomly)\", fontsize=14)\n",
    "\n",
    "plt.subplot(322)\n",
    "plot_decision_boundaries(kmeans_iter1, X, show_xlabels=False, show_ylabels=False)\n",
    "plt.title(\"Label the instances\", fontsize=14)\n",
    "\n",
    "plt.subplot(323)\n",
    "plot_decision_boundaries(kmeans_iter1, X, show_centroids=False, show_xlabels=False)\n",
    "plot_centroids(kmeans_iter2.cluster_centers_)\n",
    "\n",
    "plt.subplot(324)\n",
    "plot_decision_boundaries(kmeans_iter2, X, show_xlabels=False, show_ylabels=False)\n",
    "\n",
    "plt.subplot(325)\n",
    "plot_decision_boundaries(kmeans_iter2, X, show_centroids=False)\n",
    "plot_centroids(kmeans_iter3.cluster_centers_)\n",
    "\n",
    "plt.subplot(326)\n",
    "plot_decision_boundaries(kmeans_iter3, X, show_ylabels=False)\n",
    "\n",
    "save_fig(\"kmeans_algorithm_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original K-Means algorithm, the centroids are just initialized randomly, and the algorithm simply runs a single iteration to gradually improve the centroids, as we saw above.\n",
    "\n",
    "However, one major problem with this approach is that if you run K-Means multiple times (or with different random seeds), it can converge to very different solutions, as you can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusterer_comparison(clusterer1, clusterer2, X, title1=None, title2=None):\n",
    "    clusterer1.fit(X)\n",
    "    clusterer2.fit(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 3.2))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plot_decision_boundaries(clusterer1, X)\n",
    "    if title1:\n",
    "        plt.title(title1, fontsize=14)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plot_decision_boundaries(clusterer2, X, show_ylabels=False)\n",
    "    if title2:\n",
    "        plt.title(title2, fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_rnd_init1 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                         algorithm=\"full\", random_state=11)\n",
    "kmeans_rnd_init2 = KMeans(n_clusters=5, init=\"random\", n_init=1,\n",
    "                         algorithm=\"full\", random_state=19)\n",
    "\n",
    "plot_clusterer_comparison(kmeans_rnd_init1, kmeans_rnd_init2, X,\n",
    "                          \"Solution 1\", \"Solution 2 (with a different random init)\")\n",
    "\n",
    "save_fig(\"kmeans_variability_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the best model, we will need a way to evaluate a K-Mean model's performance. Unfortunately, clustering is an unsupervised task, so we do not have the targets. But at least we can measure the distance between each instance and its centroid. This is the idea behind the _inertia_ metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can easily verify, inertia is the sum of the squared distances between each training instance and its closest centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dist = kmeans.transform(X)\n",
    "np.sum(X_dist[np.arange(len(X_dist)), kmeans.labels_]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `score()` method returns the negative inertia. Why negative? Well, it is because a predictor's `score()` method must always respect the \"_great is better_\" rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.score(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So one approach to solve the variability issue is to simply run the K-Means algorithm multiple times with different random initializations, and select the solution that minimizes the inertia. For example, here are the inertias of the two \"bad\" models shown in the previous figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_rnd_init1.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_rnd_init2.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, they have a higher inertia than the first \"good\" model we trained, which means they are probably worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you set the `n_init` hyperparameter, Scikit-Learn runs the original algorithm `n_init` times, and selects the solution that minimizes the inertia. By default, Scikit-Learn sets `n_init=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_rnd_10_inits = KMeans(n_clusters=5, init=\"random\", n_init=10,\n",
    "                              algorithm=\"full\", random_state=11)\n",
    "kmeans_rnd_10_inits.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we end up with the initial model, which is certainly the optimal K-Means solution (at least in terms of inertia, and assuming $k=5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans_rnd_10_inits, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of initializing the centroids entirely randomly, it is preferable to initialize them using the following algorithm, proposed in a [2006 paper](https://goo.gl/eNUPw6) by David Arthur and Sergei Vassilvitskii:\n",
    "* Take one centroid $c_1$, chosen uniformly at random from the dataset.\n",
    "* Take a new center $c_i$, choosing an instance $\\mathbf{x}_i$ with probability: $D(\\mathbf{x}_i)^2$ / $\\sum\\limits_{j=1}^{m}{D(\\mathbf{x}_j)}^2$ where $D(\\mathbf{x}_i)$ is the distance between the instance $\\mathbf{x}_i$ and the closest centroid that was already chosen. This probability distribution ensures that instances that are further away from already chosen centroids are much more likely be selected as centroids.\n",
    "* Repeat the previous step until all $k$ centroids have been chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the K-Means++ algorithm is just regular K-Means. With this initialization, the K-Means algorithm is much less likely to converge to a suboptimal solution, so it is possible to reduce `n_init` considerably. Most of the time, this largely compensates for the additional complexity of the initialization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the initialization to K-Means++, simply set `init=\"k-means++\"` (this is actually the default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_init = np.array([[-3, 3], [-3, 2], [-3, 1], [-1, 2], [0, 2]])\n",
    "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1, random_state=42)\n",
    "kmeans.fit(X)\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerated K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Means algorithm can be significantly accelerated by avoiding many unnecessary distance calculations: this is achieved by exploiting the triangle inequality (given three points A, B and C, the distance AC is always such that AC â‰¤ AB + BC) and by keeping track of lower and upper bounds for distances between instances and centroids (see this [2003 paper](https://www.aaai.org/Papers/ICML/2003/ICML03-022.pdf) by Charles Elkan for more details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Elkan's variant of K-Means, just set `algorithm=\"elkan\"`. Note that it does not support sparse data, so by default, Scikit-Learn uses `\"elkan\"` for dense data, and `\"full\"` (the regular K-Means algorithm) for sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 50 KMeans(algorithm=\"elkan\").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit -n 50 KMeans(algorithm=\"full\").fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn also implements a variant of the K-Means algorithm that supports mini-batches (see [this paper](http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=5, random_state=42)\n",
    "minibatch_kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset does not fit in memory, the simplest option is to use the `memmap` class, just like we did for incremental PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_mnist.data\"\n",
    "m, n = 50000, 28*28\n",
    "X_mm = np.memmap(filename, dtype=\"float32\", mode=\"readonly\", shape=(m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=10, batch_size=10, random_state=42)\n",
    "minibatch_kmeans.fit(X_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data is so large that you cannot use `memmap`, things get more complicated. Let's start by writing a function to load the next batch (in real life, you would load the data from disk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_next_batch(batch_size):\n",
    "    return X[np.random.choice(len(X), batch_size, replace=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model by feeding it one batch at a time. We also need to implement multiple initializations and keep the model with the lowest inertia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "n_init = 10\n",
    "n_iterations = 100\n",
    "batch_size = 100\n",
    "init_size = 500  # more data for K-Means++ initialization\n",
    "evaluate_on_last_n_iters = 10\n",
    "\n",
    "best_kmeans = None\n",
    "\n",
    "for init in range(n_init):\n",
    "    minibatch_kmeans = MiniBatchKMeans(n_clusters=k, init_size=init_size)\n",
    "    X_init = load_next_batch(init_size)\n",
    "    minibatch_kmeans.partial_fit(X_init)\n",
    "\n",
    "    minibatch_kmeans.sum_inertia_ = 0\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch = load_next_batch(batch_size)\n",
    "        minibatch_kmeans.partial_fit(X_batch)\n",
    "        if iteration >= n_iterations - evaluate_on_last_n_iters:\n",
    "            minibatch_kmeans.sum_inertia_ += minibatch_kmeans.inertia_\n",
    "\n",
    "    if (best_kmeans is None or\n",
    "        minibatch_kmeans.sum_inertia_ < best_kmeans.sum_inertia_):\n",
    "        best_kmeans = minibatch_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kmeans.score(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-batch K-Means is much faster than regular K-Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit KMeans(n_clusters=5).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit MiniBatchKMeans(n_clusters=5).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's *much* faster! However, its performance is often lower (higher inertia), and it keeps degrading as _k_ increases. Let's plot the inertia ratio and the training time ratio between Mini-batch K-Means and regular K-Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.empty((100, 2))\n",
    "inertias = np.empty((100, 2))\n",
    "for k in range(1, 101):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    minibatch_kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "    print(\"\\r{}/{}\".format(k, 100), end=\"\")\n",
    "    times[k-1, 0] = timeit(\"kmeans.fit(X)\", number=10, globals=globals())\n",
    "    times[k-1, 1]  = timeit(\"minibatch_kmeans.fit(X)\", number=10, globals=globals())\n",
    "    inertias[k-1, 0] = kmeans.inertia_\n",
    "    inertias[k-1, 1] = minibatch_kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(range(1, 101), inertias[:, 0], \"r--\", label=\"K-Means\")\n",
    "plt.plot(range(1, 101), inertias[:, 1], \"b.-\", label=\"Mini-batch K-Means\")\n",
    "plt.xlabel(\"$k$\", fontsize=16)\n",
    "#plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.title(\"Inertia\", fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.axis([1, 100, 0, 100])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(range(1, 101), times[:, 0], \"r--\", label=\"K-Means\")\n",
    "plt.plot(range(1, 101), times[:, 1], \"b.-\", label=\"Mini-batch K-Means\")\n",
    "plt.xlabel(\"$k$\", fontsize=16)\n",
    "#plt.ylabel(\"Training time (seconds)\", fontsize=14)\n",
    "plt.title(\"Training time (seconds)\", fontsize=14)\n",
    "plt.axis([1, 100, 0, 6])\n",
    "#plt.legend(fontsize=14)\n",
    "\n",
    "save_fig(\"minibatch_kmeans_vs_kmeans\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the number of clusters was set to a lower or greater value than 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_k3 = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_k8 = KMeans(n_clusters=8, random_state=42)\n",
    "\n",
    "plot_clusterer_comparison(kmeans_k3, kmeans_k8, X, \"$k=3$\", \"$k=8$\")\n",
    "save_fig(\"bad_n_clusters_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch, these two models don't look great. What about their inertias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_k3.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_k8.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, we cannot simply take the value of $k$ that minimizes the inertia, since it keeps getting lower as we increase $k$. Indeed, the more clusters there are, the closer each instance will be to its closest centroid, and therefore the lower the inertia will be. However, we can plot the inertia as a function of $k$ and analyze the resulting curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "                for k in range(1, 10)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.annotate('Elbow',\n",
    "             xy=(4, inertias[3]),\n",
    "             xytext=(0.55, 0.55),\n",
    "             textcoords='figure fraction',\n",
    "             fontsize=16,\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1)\n",
    "            )\n",
    "plt.axis([1, 8.5, 0, 1300])\n",
    "save_fig(\"inertia_vs_k_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is an elbow at $k=4$, which means that less clusters than that would be bad, and more clusters would not help much and might cut clusters in half. So $k=4$ is a pretty good choice. Of course in this example it is not perfect since it means that the two blobs in the lower left will be considered as just a single cluster, but it's a pretty good clustering nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(kmeans_per_k[4-1], X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to look at the _silhouette score_, which is the mean _silhouette coefficient_ over all the instances. An instance's silhouette coefficient is equal to $(b - a)/\\max(a, b)$ where $a$ is the mean distance to the other instances in the same cluster (it is the _mean intra-cluster distance_), and $b$ is the _mean nearest-cluster distance_, that is the mean distance to the instances of the next closest cluster (defined as the one that minimizes $b$, excluding the instance's own cluster). The silhouette coefficient can vary between -1 and +1: a coefficient close to +1 means that the instance is well inside its own cluster and far from other clusters, while a coefficient close to 0 means that it is close to a cluster boundary, and finally a coefficient close to -1 means that the instance may have been assigned to the wrong cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the silhouette score as a function of $k$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.axis([1.8, 8.5, 0.55, 0.7])\n",
    "save_fig(\"silhouette_score_vs_k_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this visualization is much richer than the previous one: in particular, although it confirms that $k=4$ is a very good choice, but it also underlines the fact that $k=5$ is quite good as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even more informative visualization is given when you plot every instance's silhouette coefficient, sorted by the cluster they are assigned to and by the value of the coefficient. This is called a _silhouette diagram_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (3, 4, 5, 6):\n",
    "    plt.subplot(2, 2, k - 2)\n",
    "    \n",
    "    y_pred = kmeans_per_k[k - 1].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X, y_pred)\n",
    "\n",
    "    padding = len(X) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "\n",
    "        color = mpl.cm.Spectral(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (3, 5):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "    \n",
    "    if k in (5, 6):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(\"$k={}$\".format(k), fontsize=16)\n",
    "\n",
    "save_fig(\"silhouette_analysis_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limits of K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=1000, centers=((4, -4), (0, 0)), random_state=42)\n",
    "X1 = X1.dot(np.array([[0.374, 0.95], [0.732, 0.598]]))\n",
    "X2, y2 = make_blobs(n_samples=250, centers=1, random_state=42)\n",
    "X2 = X2 + [6, -8]\n",
    "X = np.r_[X1, X2]\n",
    "y = np.r_[y1, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_good = KMeans(n_clusters=3, init=np.array([[-1.5, 2.5], [0.5, 0], [4, 0]]), n_init=1, random_state=42)\n",
    "kmeans_bad = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_good.fit(X)\n",
    "kmeans_bad.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_decision_boundaries(kmeans_good, X)\n",
    "plt.title(\"Inertia = {:.1f}\".format(kmeans_good.inertia_), fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_decision_boundaries(kmeans_bad, X, show_ylabels=False)\n",
    "plt.title(\"Inertia = {:.1f}\".format(kmeans_bad.inertia_), fontsize=14)\n",
    "\n",
    "save_fig(\"bad_kmeans_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using clustering for image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "image = imread(os.path.join(\"images\",\"unsupervised_learning\",\"ladybug.png\"))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image.reshape(-1, 3)\n",
    "kmeans = KMeans(n_clusters=8, random_state=42).fit(X)\n",
    "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "segmented_img = segmented_img.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_imgs = []\n",
    "n_colors = (10, 8, 6, 4, 2)\n",
    "for n_clusters in n_colors:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
    "    segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "    segmented_imgs.append(segmented_img.reshape(image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original image\")\n",
    "plt.axis('off')\n",
    "\n",
    "for idx, n_clusters in enumerate(n_colors):\n",
    "    plt.subplot(232 + idx)\n",
    "    plt.imshow(segmented_imgs[idx])\n",
    "    plt.title(\"{} colors\".format(n_clusters))\n",
    "    plt.axis('off')\n",
    "\n",
    "save_fig('image_segmentation_diagram', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Clustering for Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tackle the _digits dataset_ which is a simple MNIST-like dataset containing 1,797 grayscale 8Ã—8 images representing digits 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits, y_digits = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split it into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit a Logistic Regression model and evaluate it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's our baseline: 96.7% accuracy. Let's see if we can do better by using K-Means as a preprocessing step. We will create a pipeline that will first cluster the training set into 50 clusters and replace the images with their distances to the 50 clusters, then apply a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=50, random_state=42)),\n",
    "    (\"log_reg\", LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (1 - 0.9822222) / (1 - 0.9666666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about that? We almost divided the error rate by a factor of 2! But we chose the number of clusters $k$ completely arbitrarily, we can surely do better. Since K-Means is just a preprocessing step in a classification pipeline, finding a good value for $k$ is much simpler than earlier: there's no need to perform silhouette analysis or minimize the inertia, the best value of $k$ is simply the one that results in the best classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is slightly improved when $k=90$, so 90 it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering for Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use case for clustering is in semi-supervised learning, when we have plenty of unlabeled instances and very few labeled instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the performance of a logistic regression model when we only have 50 labeled instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labeled = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's much less than earlier of course. Let's see how we can do better. First, let's cluster the training set into 50 clusters, then for each cluster let's find the image closest to the centroid. We will call these images the representative images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
    "X_representative_digits = X_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot these representative images and label them manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "for index, X_representative_digit in enumerate(X_representative_digits):\n",
    "    plt.subplot(k // 10, 10, index + 1)\n",
    "    plt.imshow(X_representative_digit.reshape(8, 8), cmap=\"binary\", interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "\n",
    "save_fig(\"representative_images_diagram\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_representative_digits = np.array([\n",
    "    4, 8, 0, 6, 8, 3, 7, 7, 9, 2,\n",
    "    5, 5, 8, 5, 2, 1, 2, 9, 6, 1,\n",
    "    1, 6, 9, 0, 8, 3, 0, 7, 4, 1,\n",
    "    6, 5, 2, 4, 1, 8, 6, 3, 9, 2,\n",
    "    4, 2, 9, 4, 7, 6, 2, 3, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataset with just 50 labeled instances, but instead of being completely random instances, each of them is a representative image of its cluster. Let's see if the performance is any better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X_representative_digits, y_representative_digits)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! We jumped from 82.7% accuracy to 92.4%, although we are still only training the model on 50 instances. Since it's often costly and painful to label instances, especially when it has to be done manually by experts, it's a good idea to make them label representative instances rather than just random instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But perhaps we can go one step further: what if we propagated the labels to all the other instances in the same cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_==i] = y_representative_digits[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X_train, y_train_propagated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a tiny little accuracy boost. Better than nothing, but we should probably have propagated the labels only to the instances closest to the centroid, because by propagating to the full cluster, we have certainly included some outliers. Let's only propagate the labels to the 20th percentile closest to the centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_closest = 20\n",
    "\n",
    "X_cluster_dist = X_digits_dist[np.arange(len(X_train)), kmeans.labels_]\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_cluster_dist[in_cluster]\n",
    "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
    "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
    "    X_cluster_dist[in_cluster & above_cutoff] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_propagated = (X_cluster_dist != -1)\n",
    "X_train_partially_propagated = X_train[partially_propagated]\n",
    "y_train_partially_propagated = y_train_propagated[partially_propagated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X_train_partially_propagated, y_train_partially_propagated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! With just 50 labeled instances (just 5 examples per class on average!), we got 94.2% performance, which is pretty close to the performance of logistic regression on the fully labeled _digits_ dataset (which was 96.7%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the propagated labels are actually pretty good: their accuracy is very close to 99%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_train_partially_propagated == y_train[partially_propagated])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could now do a few iterations of _active learning_:\n",
    "1. Manually label the instances that the classifier is least sure about, if possible by picking them in distinct clusters.\n",
    "2. Train a new model with these additional labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "dbscan.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.labels_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dbscan.core_sample_indices_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.core_sample_indices_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.components_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dbscan.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan2 = DBSCAN(eps=0.2)\n",
    "dbscan2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dbscan(dbscan, X, size, show_xlabels=True, show_ylabels=True):\n",
    "    core_mask = np.zeros_like(dbscan.labels_, dtype=bool)\n",
    "    core_mask[dbscan.core_sample_indices_] = True\n",
    "    anomalies_mask = dbscan.labels_ == -1\n",
    "    non_core_mask = ~(core_mask | anomalies_mask)\n",
    "\n",
    "    cores = dbscan.components_\n",
    "    anomalies = X[anomalies_mask]\n",
    "    non_cores = X[non_core_mask]\n",
    "    \n",
    "    plt.scatter(cores[:, 0], cores[:, 1],\n",
    "                c=dbscan.labels_[core_mask], marker='o', s=size, cmap=\"Paired\")\n",
    "    plt.scatter(cores[:, 0], cores[:, 1], marker='*', s=20, c=dbscan.labels_[core_mask])\n",
    "    plt.scatter(anomalies[:, 0], anomalies[:, 1],\n",
    "                c=\"r\", marker=\"x\", s=100)\n",
    "    plt.scatter(non_cores[:, 0], non_cores[:, 1], c=dbscan.labels_[non_core_mask], marker=\".\")\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)\n",
    "    plt.title(\"eps={:.2f}, min_samples={}\".format(dbscan.eps, dbscan.min_samples), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_dbscan(dbscan, X, size=100)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_dbscan(dbscan2, X, size=600, show_ylabels=False)\n",
    "\n",
    "save_fig(\"dbscan_diagram\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = dbscan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plot_decision_boundaries(knn, X, show_centroids=False)\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], c=\"b\", marker=\"+\", s=200, zorder=10)\n",
    "save_fig(\"cluster_classification_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1)\n",
    "y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]\n",
    "y_pred[y_dist > 0.2] = -1\n",
    "y_pred.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc1 = SpectralClustering(n_clusters=2, gamma=100, random_state=42)\n",
    "sc1.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc2 = SpectralClustering(n_clusters=2, gamma=1, random_state=42)\n",
    "sc2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(sc1.affinity_matrix_, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectral_clustering(sc, X, size, alpha, show_xlabels=True, show_ylabels=True):\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker='o', s=size, c='gray', cmap=\"Paired\", alpha=alpha)\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker='o', s=30, c='w')\n",
    "    plt.scatter(X[:, 0], X[:, 1], marker='.', s=10, c=sc.labels_, cmap=\"Paired\")\n",
    "    \n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)\n",
    "    plt.title(\"RBF gamma={}\".format(sc.gamma), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_spectral_clustering(sc1, X, size=500, alpha=0.1)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_spectral_clustering(sc2, X, size=4000, alpha=0.01, show_ylabels=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([0, 2, 5, 8.5]).reshape(-1, 1)\n",
    "agg = AgglomerativeClustering(linkage=\"complete\").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_parameters(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agg.children_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=1000, centers=((4, -4), (0, 0)), random_state=42)\n",
    "X1 = X1.dot(np.array([[0.374, 0.95], [0.732, 0.598]]))\n",
    "X2, y2 = make_blobs(n_samples=250, centers=1, random_state=42)\n",
    "X2 = X2 + [6, -8]\n",
    "X = np.r_[X1, X2]\n",
    "y = np.r_[y1, y2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Gaussian mixture model on the previous dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=3, n_init=10, random_state=42)\n",
    "gm.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the parameters that the EM algorithm estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.covariances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the algorithm actually converge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.converged_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, good. How many iterations did it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use the model to predict which cluster each instance belongs to (hard clustering) or the probabilities that it came from each cluster. For this, just use `predict()` method or the `predict_proba()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a generative model, so you can sample new instances from it (and get their labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = gm.sample(6)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that they are sampled sequentially from each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also estimate the log of the _probability density function_ (PDF) at any location using the `score_samples()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.score_samples(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the PDF integrates to 1 over the whole space. We just take a large square around the clusters, and chop it into a grid of tiny squares, then we compute the approximate probability that the instances will be generated in each tiny square (by multiplying the PDF at one corner of the tiny square by the area of the square), and finally summing all these probabilities). The result is very close to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 100\n",
    "grid = np.arange(-10, 10, 1 / resolution)\n",
    "xx, yy = np.meshgrid(grid, grid)\n",
    "X_full = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "pdf = np.exp(gm.score_samples(X_full))\n",
    "pdf_probas = pdf * (1 / resolution) ** 2\n",
    "pdf_probas.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the resulting decision boundaries (dashed lines) and density contours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def plot_gaussian_mixture(clusterer, X, resolution=1000, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = -clusterer.score_samples(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z,\n",
    "                 norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                 levels=np.logspace(0, 2, 12))\n",
    "    plt.contour(xx, yy, Z,\n",
    "                norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                levels=np.logspace(0, 2, 12),\n",
    "                linewidths=1, colors='k')\n",
    "\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z,\n",
    "                linewidths=2, colors='r', linestyles='dashed')\n",
    "    \n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "    plot_centroids(clusterer.means_, clusterer.weights_)\n",
    "\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plot_gaussian_mixture(gm, X)\n",
    "\n",
    "save_fig(\"gaussian_mixtures_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can impose constraints on the covariance matrices that the algorithm looks for by setting the `covariance_type` hyperparameter:\n",
    "* `\"full\"` (default): no constraint, all clusters can take on any ellipsoidal shape of any size.\n",
    "* `\"tied\"`: all clusters must have the same shape, which can be any ellipsoid (i.e., they all share the same covariance matrix).\n",
    "* `\"spherical\"`: all clusters must be spherical, but they can have different diameters (i.e., different variances).\n",
    "* `\"diag\"`: clusters can take on any ellipsoidal shape of any size, but the ellipsoid's axes must be parallel to the axes (i.e., the covariance matrices must be diagonal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_full = GaussianMixture(n_components=3, n_init=10, covariance_type=\"full\", random_state=42)\n",
    "gm_tied = GaussianMixture(n_components=3, n_init=10, covariance_type=\"tied\", random_state=42)\n",
    "gm_spherical = GaussianMixture(n_components=3, n_init=10, covariance_type=\"spherical\", random_state=42)\n",
    "gm_diag = GaussianMixture(n_components=3, n_init=10, covariance_type=\"diag\", random_state=42)\n",
    "gm_full.fit(X)\n",
    "gm_tied.fit(X)\n",
    "gm_spherical.fit(X)\n",
    "gm_diag.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_gaussian_mixtures(gm1, gm2, X):\n",
    "    plt.figure(figsize=(9, 4))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plot_gaussian_mixture(gm1, X)\n",
    "    plt.title('covariance_type=\"{}\"'.format(gm1.covariance_type), fontsize=14)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plot_gaussian_mixture(gm2, X, show_ylabels=False)\n",
    "    plt.title('covariance_type=\"{}\"'.format(gm2.covariance_type), fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_gaussian_mixtures(gm_tied, gm_spherical, X)\n",
    "\n",
    "save_fig(\"covariance_type_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_gaussian_mixtures(gm_full, gm_diag, X)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection using Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Mixtures can be used for _anomaly detection_: instances located in low-density regions can be considered anomalies. You must define what density threshold you want to use. For example, in a manufacturing company that tries to detect defective products, the ratio of defective products is usually well-known. Say it is equal to 4%, then you can set the density threshold to be the value that results in having 4% of the instances located in areas below that threshold density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = gm.score_samples(X)\n",
    "density_threshold = np.percentile(densities, 4)\n",
    "anomalies = X[densities < density_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plot_gaussian_mixture(gm, X)\n",
    "plt.scatter(anomalies[:, 0], anomalies[:, 1], color='r', marker='*')\n",
    "plt.ylim(top=5.1)\n",
    "\n",
    "save_fig(\"mixture_anomaly_detection_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot use the inertia or the silhouette score because they both assume that the clusters are spherical. Instead, we can try to find the model that minimizes a theoretical information criterion such as the Bayesian Information Criterion (BIC) or the Akaike Information Criterion (AIC):\n",
    "\n",
    "${BIC} = {\\log(m)p - 2\\log({\\hat L})}$\n",
    "\n",
    "${AIC} = 2p - 2\\log(\\hat L)$\n",
    "\n",
    "* $m$ is the number of instances.\n",
    "* $p$ is the number of parameters learned by the model.\n",
    "* $\\hat L$ is the maximized value of the likelihood function of the model. This is the conditional probability of the observed data $\\mathbf{X}$, given the model and its optimized parameters.\n",
    "\n",
    "Both BIC and AIC penalize models that have more parameters to learn (e.g., more clusters), and reward models that fit the data well (i.e., models that give a high likelihood to the observed data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.bic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.aic(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could compute the BIC manually like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "n_dims = 2\n",
    "n_params_for_weights = n_clusters - 1\n",
    "n_params_for_means = n_clusters * n_dims\n",
    "n_params_for_covariance = n_clusters * n_dims * (n_dims + 1) // 2\n",
    "n_params = n_params_for_weights + n_params_for_means + n_params_for_covariance\n",
    "max_log_likelihood = gm.score(X) * len(X) # log(L^)\n",
    "bic = np.log(len(X)) * n_params - 2 * max_log_likelihood\n",
    "aic = 2 * n_params - 2 * max_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one weight per cluster, but the sum must be equal to 1, so we have one degree of freedom less, hence the -1. Similarly, the degrees of freedom for an $n \\times n$ covariance matrix is not $n^2$, but $1 + 2 + \\dots + n = \\dfrac{n (n+1)}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train Gaussian Mixture models with various values of $k$ and measure their BIC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gms_per_k = [GaussianMixture(n_components=k, n_init=10, random_state=42).fit(X)\n",
    "             for k in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bics = [model.bic(X) for model in gms_per_k]\n",
    "aics = [model.aic(X) for model in gms_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(1, 11), bics, \"bo-\", label=\"BIC\")\n",
    "plt.plot(range(1, 11), aics, \"go--\", label=\"AIC\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Information Criterion\", fontsize=14)\n",
    "plt.axis([1, 9.5, np.min(aics) - 50, np.max(aics) + 50])\n",
    "plt.annotate('Minimum',\n",
    "             xy=(3, bics[2]),\n",
    "             xytext=(0.35, 0.6),\n",
    "             textcoords='figure fraction',\n",
    "             fontsize=14,\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1)\n",
    "            )\n",
    "plt.legend()\n",
    "save_fig(\"aic_bic_vs_k_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search for best combination of values for both the number of clusters and the `covariance_type` hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bic = np.infty\n",
    "\n",
    "for k in range(1, 11):\n",
    "    for covariance_type in (\"full\", \"tied\", \"spherical\", \"diag\"):\n",
    "        bic = GaussianMixture(n_components=k, n_init=10,\n",
    "                              covariance_type=covariance_type,\n",
    "                              random_state=42).fit(X).bic(X)\n",
    "        if bic < min_bic:\n",
    "            min_bic = bic\n",
    "            best_k = k\n",
    "            best_covariance_type = covariance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_covariance_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayesian Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than manually searching for the optimal number of clusters, it is possible to use instead the `BayesianGaussianMixture` class which is capable of giving weights equal (or close) to zero to unnecessary clusters. Just set the number of components to a value that you believe is greater than the optimal number of clusters, and the algorithm will eliminate the unnecessary clusters automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(n_components=10, n_init=10, random_state=42)\n",
    "bgm.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm automatically detected that only 3 components are needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(bgm.weights_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plot_gaussian_mixture(bgm, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm_low = BayesianGaussianMixture(n_components=10, max_iter=1000, n_init=1,\n",
    "                                  weight_concentration_prior=0.01, random_state=42)\n",
    "bgm_high = BayesianGaussianMixture(n_components=10, max_iter=1000, n_init=1,\n",
    "                                  weight_concentration_prior=10000, random_state=42)\n",
    "nn = 73\n",
    "bgm_low.fit(X[:nn])\n",
    "bgm_high.fit(X[:nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(bgm_low.weights_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(bgm_high.weights_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_gaussian_mixture(bgm_low, X[:nn])\n",
    "plt.title(\"weight_concentration_prior = 0.01\", fontsize=14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_gaussian_mixture(bgm_high, X[:nn], show_ylabels=False)\n",
    "plt.title(\"weight_concentration_prior = 10000\", fontsize=14)\n",
    "\n",
    "save_fig(\"mixture_concentration_prior_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the fact that you see only 3 regions in the right plot although there are 4 centroids is not a bug. The weight of the top-right cluster is much larger than the weight of the lower-right cluster, so the probability that any given point in this region belongs to the top right cluster is greater than the probability that it belongs to the lower-right cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons, y_moons = make_moons(n_samples=1000, noise=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(n_components=10, n_init=10, random_state=42)\n",
    "bgm.fit(X_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3.2))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_data(X_moons)\n",
    "plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_gaussian_mixture(bgm, X_moons, show_ylabels=False)\n",
    "\n",
    "save_fig(\"moons_vs_bgm_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, not great... instead of detecting 2 moon-shaped clusters, the algorithm detected 8 ellipsoidal clusters. However, the density plot does not look too bad, so it might be usable for anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(-6, 4, 101)\n",
    "ss = np.linspace(1, 2, 101)\n",
    "XX, SS = np.meshgrid(xx, ss)\n",
    "ZZ = 2 * norm.pdf(XX - 1.0, 0, SS) + norm.pdf(XX + 4.0, 0, SS)\n",
    "ZZ = ZZ / ZZ.sum(axis=1) / (xx[1] - xx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "\n",
    "plt.figure(figsize=(8, 4.5))\n",
    "\n",
    "x_idx = 85\n",
    "s_idx = 30\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.contourf(XX, SS, ZZ, cmap=\"GnBu\")\n",
    "plt.plot([-6, 4], [ss[s_idx], ss[s_idx]], \"k-\", linewidth=2)\n",
    "plt.plot([xx[x_idx], xx[x_idx]], [1, 2], \"b-\", linewidth=2)\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$\\theta$\", fontsize=14, rotation=0)\n",
    "plt.title(r\"Model $f(x; \\theta)$\", fontsize=14)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(ss, ZZ[:, x_idx], \"b-\")\n",
    "max_idx = np.argmax(ZZ[:, x_idx])\n",
    "max_val = np.max(ZZ[:, x_idx])\n",
    "plt.plot(ss[max_idx], max_val, \"r.\")\n",
    "plt.plot([ss[max_idx], ss[max_idx]], [0, max_val], \"r:\")\n",
    "plt.plot([0, ss[max_idx]], [max_val, max_val], \"r:\")\n",
    "plt.text(1.01, max_val + 0.005, r\"$\\hat{L}$\", fontsize=14)\n",
    "plt.text(ss[max_idx]+ 0.01, 0.055, r\"$\\hat{\\theta}$\", fontsize=14)\n",
    "plt.text(ss[max_idx]+ 0.01, max_val - 0.012, r\"$Max$\", fontsize=12)\n",
    "plt.axis([1, 2, 0.05, 0.15])\n",
    "plt.xlabel(r\"$\\theta$\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.text(1.99, 0.135, r\"$=f(x=2.5; \\theta)$\", fontsize=14, ha=\"right\")\n",
    "plt.title(r\"Likelihood function $\\mathcal{L}(\\theta|x=2.5)$\", fontsize=14)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(xx, ZZ[s_idx], \"k-\")\n",
    "plt.axis([-6, 4, 0, 0.25])\n",
    "plt.xlabel(r\"$x$\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.title(r\"PDF $f(x; \\theta=1.3)$\", fontsize=14)\n",
    "verts = [(xx[41], 0)] + list(zip(xx[41:81], ZZ[s_idx, 41:81])) + [(xx[80], 0)]\n",
    "poly = Polygon(verts, facecolor='0.9', edgecolor='0.5')\n",
    "plt.gca().add_patch(poly)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(ss, np.log(ZZ[:, x_idx]), \"b-\")\n",
    "max_idx = np.argmax(np.log(ZZ[:, x_idx]))\n",
    "max_val = np.max(np.log(ZZ[:, x_idx]))\n",
    "plt.plot(ss[max_idx], max_val, \"r.\")\n",
    "plt.plot([ss[max_idx], ss[max_idx]], [-5, max_val], \"r:\")\n",
    "plt.plot([0, ss[max_idx]], [max_val, max_val], \"r:\")\n",
    "plt.axis([1, 2, -2.4, -2])\n",
    "plt.xlabel(r\"$\\theta$\", fontsize=14)\n",
    "plt.text(ss[max_idx]+ 0.01, max_val - 0.05, r\"$Max$\", fontsize=12)\n",
    "plt.text(ss[max_idx]+ 0.01, -2.39, r\"$\\hat{\\theta}$\", fontsize=14)\n",
    "plt.text(1.01, max_val + 0.02, r\"$\\log \\, \\hat{L}$\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.title(r\"$\\log \\, \\mathcal{L}(\\theta|x=2.5)$\", fontsize=14)\n",
    "\n",
    "save_fig(\"likelihood_function_diagram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Load the MNIST dataset (introduced in chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset was loaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist['data'][:60000]\n",
    "y_train = mnist['target'][:60000]\n",
    "\n",
    "X_test = mnist['data'][60000:]\n",
    "y_test = mnist['target'][60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Next, use PCA to reduce the dataset's dimensionality, with an explained variance ratio of 95%.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf2 = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "t0 = time.time()\n",
    "rnd_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! Training is actually more than twice slower now! How can that be? Well, as we saw in this chapter, dimensionality reduction does not always lead to faster training time: it depends on the dataset, the model and the training algorithm. See figure 8-6 (the `manifold_decision_boundary_plot*` plots above). If you try a softmax classifier instead of a random forest classifier, you will find that training time is reduced by a factor of 3 when using PCA. Actually, we will do this in a second, but first let's check the precision of the new random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Next evaluate the classifier on the test set: how does it compare to the previous classifier?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "y_pred = rnd_clf2.predict(X_test_reduced)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common for performance to drop slightly when reducing dimensionality, because we do lose some useful signal in the process. However, the performance drop is rather severe in this case. So PCA really did not help: it slowed down training and reduced performance. :(\n",
    "\n",
    "Let's see if it helps when using softmax regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "t0 = time.time()\n",
    "log_clf.fit(X_train, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so softmax regression takes much longer to train on this dataset than the random forest classifier, plus it performs worse on the test set. But that's not what we are interested in right now, we want to see how much PCA can help softmax regression. Let's train the softmax regression model using the reduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf2 = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "t0 = time.time()\n",
    "log_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Reducing dimensionality led to a 4Ã— speedup. :)  Let's check the model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_clf2.predict(X_test_reduced)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very slight drop in performance, which might be a reasonable price to pay for a 4Ã— speedup, depending on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there you have it: PCA can give you a formidable speedup... but not always!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib. You can use a scatterplot using 10 different colors to represent each image's target class.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset was loaded above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction on the full 60,000 images takes a very long time, so let's only do this on a random subset of 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "m = 10000\n",
    "idx = np.random.permutation(60000)[:m]\n",
    "\n",
    "X = mnist['data'][idx]\n",
    "y = mnist['target'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use t-SNE to reduce dimensionality down to 2D so we can plot the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use Matplotlib's `scatter()` function to plot a scatterplot, using a different color for each digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap=\"jet\")\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't this just beautiful? :) This plot tells us which numbers are easily distinguishable from the others (e.g., 0s, 6s, and most 8s are rather well separated clusters), and it also tells us which numbers are often hard to distinguish (e.g., 4s and 9s, 5s and 3s, and so on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on digits 3 and 5, which seem to overlap a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "cmap = mpl.cm.get_cmap(\"jet\")\n",
    "for digit in (2, 3, 5):\n",
    "    plt.scatter(X_reduced[y == digit, 0], X_reduced[y == digit, 1], c=[cmap(digit / 9)])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can produce a nicer image by running t-SNE on these 3 digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (y == 2) | (y == 3) | (y == 5) \n",
    "X_subset = X[idx]\n",
    "y_subset = y[idx]\n",
    "\n",
    "tsne_subset = TSNE(n_components=2, random_state=42)\n",
    "X_subset_reduced = tsne_subset.fit_transform(X_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "for digit in (2, 3, 5):\n",
    "    plt.scatter(X_subset_reduced[y_subset == digit, 0], X_subset_reduced[y_subset == digit, 1], c=[cmap(digit / 9)])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, now the clusters have far less overlap. But some 3s are all over the place. Plus, there are two distinct clusters of 2s, and also two distinct clusters of 5s. It would be nice if we could visualize a few digits from each cluster, to understand why this is the case. Let's do that now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Exercise: Alternatively, you can write colored digits at the location of each instance, or even plot scaled-down versions of the digit images themselves (if you plot all digits, the visualization will be too cluttered, so you should either draw a random sample or plot an instance only if no other instance has already been plotted at a close distance). You should get a nice visualization with well-separated clusters of digits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `plot_digits()` function that will draw a scatterplot (similar to the above scatterplots) plus write colored digits, with a minimum distance guaranteed between these digits. If the digit images are provided, they are plotted instead. This implementation was inspired from one of Scikit-Learn's excellent examples ([plot_lle_digits](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html), based on a different digit dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "\n",
    "def plot_digits(X, y, min_distance=0.05, images=None, figsize=(13, 10)):\n",
    "    # Let's scale the input features so that they range from 0 to 1\n",
    "    X_normalized = MinMaxScaler().fit_transform(X)\n",
    "    # Now we create the list of coordinates of the digits plotted so far.\n",
    "    # We pretend that one is already plotted far away at the start, to\n",
    "    # avoid `if` statements in the loop below\n",
    "    neighbors = np.array([[10., 10.]])\n",
    "    # The rest should be self-explanatory\n",
    "    plt.figure(figsize=figsize)\n",
    "    cmap = mpl.cm.get_cmap(\"jet\")\n",
    "    digits = np.unique(y)\n",
    "    for digit in digits:\n",
    "        plt.scatter(X_normalized[y == digit, 0], X_normalized[y == digit, 1], c=[cmap(digit / 9)])\n",
    "    plt.axis(\"off\")\n",
    "    ax = plt.gcf().gca()  # get current axes in current figure\n",
    "    for index, image_coord in enumerate(X_normalized):\n",
    "        closest_distance = np.linalg.norm(np.array(neighbors) - image_coord, axis=1).min()\n",
    "        if closest_distance > min_distance:\n",
    "            neighbors = np.r_[neighbors, [image_coord]]\n",
    "            if images is None:\n",
    "                plt.text(image_coord[0], image_coord[1], str(int(y[index])),\n",
    "                         color=cmap(y[index] / 9), fontdict={\"weight\": \"bold\", \"size\": 16})\n",
    "            else:\n",
    "                image = images[index].reshape(28, 28)\n",
    "                imagebox = AnnotationBbox(OffsetImage(image, cmap=\"binary\"), image_coord)\n",
    "                ax.add_artist(imagebox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it! First let's just write colored digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_reduced, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's okay, but not that beautiful. Let's try with the digit images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_reduced, y, images=X, figsize=(35, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_subset_reduced, y_subset, images=X_subset, figsize=(22, 22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with PCA. We will also time how long it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "X_pca_reduced = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"PCA took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_pca_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, PCA is blazingly fast! But although we do see a few clusters, there's way too much overlap. Let's try LLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "t0 = time.time()\n",
    "X_lle_reduced = LocallyLinearEmbedding(n_components=2, random_state=42).fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"LLE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_lle_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a while, and the result does not look too good. Let's see what happens if we apply PCA first, preserving 95% of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca_lle = Pipeline([\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"lle\", LocallyLinearEmbedding(n_components=2, random_state=42)),\n",
    "])\n",
    "t0 = time.time()\n",
    "X_pca_lle_reduced = pca_lle.fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"PCA+LLE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_pca_lle_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is more or less the same, but this time it was almost 4Ã— faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try MDS. It's much too long if we run it on 10,000 instances, so let's just try 2,000 for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "m = 2000\n",
    "t0 = time.time()\n",
    "X_mds_reduced = MDS(n_components=2, random_state=42).fit_transform(X[:m])\n",
    "t1 = time.time()\n",
    "print(\"MDS took {:.1f}s (on just 2,000 MNIST images instead of 10,000).\".format(t1 - t0))\n",
    "plot_digits(X_mds_reduced, y[:m])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meh. This does not look great, all clusters overlap too much. Let's try with PCA first, perhaps it will be faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca_mds = Pipeline([\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"mds\", MDS(n_components=2, random_state=42)),\n",
    "])\n",
    "t0 = time.time()\n",
    "X_pca_mds_reduced = pca_mds.fit_transform(X[:2000])\n",
    "t1 = time.time()\n",
    "print(\"PCA+MDS took {:.1f}s (on 2,000 MNIST images).\".format(t1 - t0))\n",
    "plot_digits(X_pca_mds_reduced, y[:2000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result, and no speedup: PCA did not help (or hurt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "t0 = time.time()\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=2).fit_transform(X, y)\n",
    "t1 = time.time()\n",
    "print(\"LDA took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_lda_reduced, y, figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is very fast, and it looks nice at first, until you realize that several clusters overlap severely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it's pretty clear that t-SNE won this little competition, wouldn't you agree? We did not time it, so let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "t0 = time.time()\n",
    "X_tsne_reduced = TSNE(n_components=2, random_state=42).fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"t-SNE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_tsne_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's twice slower than LLE, but still much faster than MDS, and the result looks great. Let's see if a bit of PCA can speed it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tsne = Pipeline([\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"tsne\", TSNE(n_components=2, random_state=42)),\n",
    "])\n",
    "t0 = time.time()\n",
    "X_pca_tsne_reduced = pca_tsne.fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"PCA+t-SNE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_pca_tsne_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, PCA roughly gave us a 25% speedup, without damaging the result. We have a winner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
